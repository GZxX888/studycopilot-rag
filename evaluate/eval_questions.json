[
  {
    "id": "Q1",
    "question": "What is a decision boundary in a neural network?",
    "should_answer": true
  },
  {
    "id": "Q2",
    "question": "What are weights and bias in a neuron used for?",
    "should_answer": true
  },
  {
    "id": "Q3",
    "question": "What is the AND gate example used to illustrate in Lecture 02?",
    "should_answer": true
  },
  {
    "id": "Q4",
    "question": "What does changing the bias do to a linear decision boundary?",
    "should_answer": true
  },
  {
    "id": "Q5",
    "question": "What is the role of an activation function in a neural network?",
    "should_answer": true
  },
  {
    "id": "Q6",
    "question": "What is the sigmoid activation function?",
    "should_answer": true
  },
  {
    "id": "Q7",
    "question": "What does horizontal scaling mean for a sigmoid function?",
    "should_answer": true
  },
  {
    "id": "Q8",
    "question": "What does it mean when a neural network has sufficient expressive power?",
    "should_answer": true
  },
  {
    "id": "Q9",
    "question": "What is the goal of training a neural network?",
    "should_answer": true
  },
  {
    "id": "Q10",
    "question": "What is the learning rate used for in gradient-based optimization?",
    "should_answer": true
  },
  {
  "id": "Q11",
  "question": "Why is it difficult to visualize a decision boundary in four-dimensional space?",
  "should_answer": true
  },
  {
  "id": "Q12",
  "question": "How does changing the learning rate affect gradient-based optimization?",
  "should_answer": true
  },
  {
  "id": "Q13",
  "question": "What is the relationship between loss function, gradient, and parameter update in neural network training?",
  "should_answer": true
  },
  {
  "id": "Q14",
  "question": "What does the AND gate example demonstrate about linear separability?",
  "should_answer": true
  },
  {
  "id": "Q15",
  "question": "What is the architecture of the ResNet-50 model discussed in the lecture slides?",
  "should_answer": false
  }
]
